# 예제 02 — LALR + PEG(부분)로 f-string 파싱하기

이 예제는 **기본 LALR(1) 파서**에 **PEG 블록**을 국소적으로 섞어 쓰는 방법을 보여줍니다.

* LALR은 전체 언어의 뼈대를 담당하고,
* 문자열 리터럴(f-string)처럼 **백트래킹이 유리한 부분만** PEG로 처리합니다.

아래 `.g` 파일은 **고등학생/초심자**도 이해할 수 있도록 **모든 줄에 주석**을 붙였습니다.

---

## 1) 예제 문법 파일: `examples/example02_peg.g`

```ebnf
// === 토큰 선언(정규식 기반) ===============================================
%token NUMBER /(?>0|[1-9][0-9_]*)(?:\.[0-9_]+)?(?:[eE][+\-]?[0-9_]+)?/;   // 10, 3.14, 6.02e23 같은 숫자
%token IDENT  /[^\W\d][\w]*/;                                            // 유니코드 식별자: 첫 글자 문자, 이후 문자/숫자/_
%ignore /\s+/;                                                             // 공백/개행/탭은 모두 무시

// === 리터럴 키워드(연산자/구두점) ============================================
"(" : "(";   // 여는 괄호
")" : ")";   // 닫는 괄호
"+" : "+";   // 덧셈
"-" : "-";   // 뺄셈(이항), 단항 음수는 아래 %right UMINUS 로 처리
"*" : "*";   // 곱셈
"/" : "/";   // 나눗셈
"^" : "^";   // 거듭제곱(오른쪽 결합)
"=" : "=";   // 대입
";" : ";";   // 문장 끝
"let":"let"; // 변수 선언 키워드 (영문)
"print":"print"; // 출력 함수처럼 쓸 키워드(간단 데모용)

// === 우선순위/결합성(템플릿 + 가상 라벨) ===================================
%use precedence cpp_core;  // 표준 C/CPP 연산자 우선순위 템플릿을 재사용(+, -, *, /, ^, UMINUS 등)
%right UMINUS;             // 단항 마이너스는 오른쪽 결합으로 취급

// === 오류 복구(선택) =========================================================
%recover panic;            // 패닉 모드: 에러 발생 시 동기화 토큰까지 스킵하며 계속
%sync ")", ";", "$";    // 동기화 토큰: 닫는 괄호/세미콜론/EOF에 맞춰 복구

// === PEG 토큰: f-string 전용 =================================================
//  - trigger='f': 입력이 'f'로 시작할 때만 PEG 실행 → "f\"...\"" 만 잡히고 일반 "\"...\"" 는 무시
//  - PEG 블록 FStr의 규칙 FString(아래 정의)을 사용해 f-string을 인식
%token FSTRING %peg(FStr.FString) [trigger='f'];

// === PEG 블록 정의(부분 백트래킹) ===========================================
%peg FStr {
  FString <- 'f'? '"' ( '{{' / '}}' / '{' (!'}' .)* '}' / [^"] )* '"'
};
// 간단한 f-string 구문: f" ... { ... } ... "
//  - 'f'는 옵션이지만, 위에서 trigger='f'로 묶었으니 실제 토큰화는 f"..."만 매치됨
//  - 중괄호 {{ 와 }} 는 이스케이프 용도(문자 그대로 {, } 출력)
//  - { ... } 안에는 } 만 나오지 않으면 어떤 문자든 허용(간단 버전)


// === 문법 본문(전역은 LALR 파서) ============================================
// 프로그램: 여러 문장으로 구성
Prog    : Stmt* ;

// 문장: 변수 선언/대입 또는 print 호출 (실행은 본 예제에서 다루지 않음 — 파싱만)
Stmt    : "let" IDENT "=" Expr ";"
        | "print" "(" Expr ")" ";"
        ;

// 식: +, - 가 Term 위에 있고, Term 은 *, / 위, Pow 는 ^ 위 — 우선순위 계층(사다리)
Expr    : Expr "+" Term
        | Expr "-" Term
        | Term
        ;

Term    : Term "*" Pow
        | Term "/" Pow
        | Pow
        ;

Pow     : Factor "^" Pow   // ^ 은 오른쪽 결합이므로 오른쪽 재귀 형태
        | Factor
        ;

// 기본 단위: 숫자, 식별자, 괄호식, f-string(PEG 토큰)
//  - FSTRING 은 위에서 %token 으로 선언한 PEG 토큰 이름
Factor  : NUMBER
        | IDENT
        | "(" Expr ")"
        | FSTRING            // ★ 여기서 PEG 런타임이 동작하여 f"..." 한 덩어리로 인식
        | "-" Factor %prec UMINUS
        ;
```

> 💡 **핵심 요지**: 전체 파서는 **LALR**로 동작하지만, `FSTRING` 토큰만은 **PEG 런타임**이 백트래킹하며 토큰화합니다. 이 방식은 복잡한 문자열/템플릿 리터럴 등을 안전하게 다룰 때 유익합니다.

---

## 2) 어떻게 동작하나요?

1. **키워드/정규식 토큰**으로 대부분의 토큰을 나눕니다.
2. `FSTRING` 위치에서만 **PEG 엔진**을 불러 f-string 정합을 확인하고, 최장 매치를 한 번에 토큰으로 반환합니다.
3. LALR 파서는 `FSTRING`을 **일반 토큰**처럼 소비하므로, 파서 테이블은 깨끗하게 유지됩니다(충돌 없음).
4. **오류 복구**가 활성화되어 있다면, 구문 오류 시 `)`, `;`, `EOF`에서 입력/스택을 동기화해 다음 문장으로 진행합니다.

---

## 3) 실행 방법

> 아래 명령은 리포지토리 루트 기준이며, 이미 `lepta`가 로컬 실행 가능하다고 가정합니다.

### (1) 테이블 확인

```bash
python -m lepta.leptac check examples/example02_peg.g --parser lalr -D
```

* `-D` : AST/BNF 요약과 상태 수, 충돌 여부를 자세히 출력합니다.

### (2) Rust 코드 방출(+ 내장 렉서 포함)

```bash
python -m lepta.leptac build examples/example02_peg.g \
  --parser lalr --lang rust --with-lexer -o out/parser.rs -D
```

* `--with-lexer` 를 쓰면 **생성된 `parser.rs` 안에** LALR 파서 런타임과 함께
  **PEG 연동 가능한 간단 렉서**가 포함됩니다. 이 렉서는 `%ignore`, 키워드 최장일치,
  그리고 **PEG 토큰 실행(백트래킹)** 을 지원합니다.

### (3) (선택) 간단 실행기(Rust) 붙여 보기

> 아래는 토큰 종류만 흘려보내 파서가 “구조상 OK인지” 확인하는 최소 예시입니다.

```rust
mod parser;                      // 위에서 생성한 out/parser.rs 를 같은 디렉터리에 둔다고 가정
use parser::{parse, Lexer, SimpleLexer, TERM_NAMES};

fn main() {
    // f-string 과 일반 식을 섞은 입력(파싱만, 실제 계산/치환은 본 예제 범위 밖)
    let src = r#"
        let name = f"hello {user}";
        print(name);
        print(1 + 2 * 3);
    "#;

    let mut lx = SimpleLexer::new(src);
    match parse(&mut lx) {
        Ok(()) => println!("OK: parsed"),
        Err(e) => eprintln!("ERR: state={}, lookahead={}", e.state, TERM_NAMES[e.lookahead as usize]),
    }
}
```

> ⚠️ **주의**: 위 코드는 “파싱 성공/실패”만 확인합니다. f-string의 중괄호 안(예: `{user}`)을 실제로
> 치환하거나 평가하려면, `parse_with_actions` API를 사용해 **세만틱 액션**을 붙이면 됩니다.

---

## 4) 입력 예시

```text
let user = f"{name}";
print(user);
print(1 + (2 ^ 3) - 4);
```

* 첫 줄: `FSTRING` 토큰이 **한 번에** 잡혀 `let user = <FSTRING> ;` 꼴로 파싱됩니다.
* 둘째/셋째 줄: 일반 LALR 사다리로 수식이 파싱됩니다.

---

## 5) FAQ

**Q. 왜 `trigger='f'` 가 필요한가요?**
A. `"\"...\""` 같은 일반 문자열을 **다른 방식으로 토큰화**하고 싶을 수 있습니다. 트리거를 쓰면
`f"..."` 로 시작하는 경우에만 PEG를 돌려 **성능과 오인식 위험**을 줄일 수 있습니다.

**Q. 유니코드 키워드(예: 한국어 키워드)를 써도 되나요?**
A. 됩니다. `"출력":"출력";` 처럼 추가하면 됩니다. 렉서가 **유니코드 단어 경계**를 인식해
식별자 중간에서 잘못 매칭되지 않도록 보호합니다.

**Q. f-string 안에서 중괄호를 문자 그대로 쓰려면?**
A. `{{` 와 `}}` 를 쓰세요(PEG 블록에 이스케이프 규칙 반영).

**Q. 실제로 `{name}` 같은 변수를 평가하려면?**
A. 파서는 구문만 인식합니다. 값 계산/치환은 실행기에서 `parse_with_actions` 와
사용자 환경(변수 테이블)을 연결해 처리합니다.

---

## 6) 정리

* **LALR** 로 전체 언어 구조를 안전하고 빠르게 인식합니다.
* **PEG** 는 **필요한 부분에만** 적용하여 복잡한 리터럴(여기서는 f-string)을 유연하게 다룹니다.
* 생성된 Rust 코드(`--with-lexer`)는 **PEG 토큰**을 실제로 실행(백트래킹)하여 f-string을 올바르게 토큰화합니다.

> 다음 단계: `parse_with_actions` 로 f-string 내부를 토크나이즈/해석하여 런타임 치환까지 구현해 보세요!

```
```
